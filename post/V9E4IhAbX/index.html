<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>深入理解 Spark SQL 的 Catalyst Optimizer | 云程的BLOG</title>
<link rel="shortcut icon" href="https://yuncheng1998.github.io/favicon.ico?v=1635939080624">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://yuncheng1998.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="深入理解 Spark SQL 的 Catalyst Optimizer | 云程的BLOG - Atom Feed" href="https://yuncheng1998.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">


<script async src="https://www.googletagmanager.com/gtag/js?id=UA-144214379-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-144214379-1');
</script>


    <meta name="description" content="Deep Dive into Spark SQL’s Catalyst Optimizer
前言

Spark SQL 的核心是Catalyst 优化器，它以一种全新的方式利用高级语言的特性（例如：Scala 的模式匹配和Quasiquot..." />
    <meta name="keywords" content="Spark,大数据" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://yuncheng1998.github.io">
  <img class="avatar" src="https://yuncheng1998.github.io/images/avatar.png?v=1635939080624" alt="">
  </a>
  <h1 class="site-title">
    云程的BLOG
  </h1>
  <p class="site-description">
    潜龙勿用
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              深入理解 Spark SQL 的 Catalyst Optimizer
            </h2>
            <div class="post-info">
              <span>
                2021-05-12
              </span>
              <span>
                8 min read
              </span>
              
                <a href="https://yuncheng1998.github.io/tag/oIQDOkfPV/" class="post-tag">
                  # Spark
                </a>
              
                <a href="https://yuncheng1998.github.io/tag/oPb0H1bRX/" class="post-tag">
                  # 大数据
                </a>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <p><a href="https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html">Deep Dive into Spark SQL’s Catalyst Optimizer</a></p>
<h1 id="前言">前言</h1>
<blockquote>
<p><em>Spark SQL</em> 的核心是<em>Catalyst</em> 优化器，它以一种全新的方式利用高级语言的特性（例如：<em>Scala</em> 的模式匹配和<em>Quasiquotes</em>）构建一个可扩展的查询优化器。</p>
</blockquote>
<p>Spark SQL架构图<br>
<img src="https://yuncheng1998.github.io/post-images/1620289726602.svg" alt="" loading="lazy"><br>
<em>Catalyst</em> 核心是<strong>表示树</strong>和<strong>操作树的规则</strong>。在框架的顶层，构建了专门用于关系型查询处理的库（表达式，逻辑查询计划）以及处理查询执行的不同阶段的几组规则（分析，逻辑优化，物理计划和将部分查询编译为 Java 字节码的代码生成）。对于后者，我们使用了另一个 <em>Scala</em> 特性<em>Quasiquotes</em>，它使得在运行时从组合表达式生成代码机器变得非常简单。最后，<em>Catalyst</em> 提供了若干公共的扩展点，包括扩展数据源和用户自定义类型。</p>
<h1 id="catalyst-的核心"><em>Catalyst</em> 的核心</h1>
<h2 id="树">树</h2>
<p>Catalyst 中的主要数据类型是<strong>由节点对象组成的树</strong>。每个节点有<strong>一个节点类型</strong>和<strong>零个或多个子节点</strong>。新的节点类型在 Scala 中定义为 TreeNode 类的子类。这些对象是不可变的，可以使用函数转换进行操作</p>
<p>举个简单的例子，假设我们有以下三个节点类型，可以用更简化的表达式表示为：</p>
<ul>
<li><code>Literal(value: Int)</code>：代表常量</li>
<li><code>Attribute(name: String)</code>：代表输入一行数据的一个属性，例如：“x”</li>
<li><code>Add(left: TreeNode, right: TreeNode)</code>：对两个表达式加和</li>
</ul>
<p>这些类构建成树；例如，表达式 <code>x+(1+2)</code>，可以在 Scala 代码中表示为：<br>
<img src="https://yuncheng1998.github.io/post-images/1620289407166.png" alt="" loading="lazy"></p>
<h2 id="规则">规则</h2>
<p>规则用于对树进行操作，是一个将一棵树转换为另外一棵树的方法。最常见的方式是<strong>使用一组模式匹配函数</strong>，找到并替换<strong>特定结构的子树</strong>。模式匹配是许多函数式编程语言的特性，允许从代数数据类型的嵌套结构中进行值提取。在<em>Catalyst</em> 中，树提供的转换方法可以递归地应用模式匹配函数到树的所有节点。例如，我们可以实现一个常量合并操作的规则：</p>
<pre><code class="language-scala">tree.transform {
  case Add(Literal(c1), Literal(c2)) =&gt; Literal(c1+c2)
}
</code></pre>
<p>这条规则将树 <code>x+(1+2)</code>转换为一颗新树：<code>x+3</code>。实践中，规则需要执行多次才能完全转换一棵树。<em>Catalyst</em> 将规则分成批次，执行各个批次直到树不再更新为止。每条规则可以非常简单且是自包含的，但最终仍会在树上产生比较大的全局效果。在上面的例子中，就重复地应用规则不断折叠一棵大树。</p>
<p>另一个例子：第一个批次分析一个表达式并将类型赋给所有属性，而第二个批次可能使用这些类型进行不断折叠。每个批次之后，开发者还可以在生成的新树上运行健全性检查（例如，查看所有的属性都指定了类型），通常这也同样通过递归匹配来编写。</p>
<h1 id="在-spark-sql-中的使用">在 <em>Spark SQL</em> 中的使用</h1>
<p>我们在四个阶段使用了 Catalyst 通用树转换操作框架</p>
<ol>
<li>分析：语法树和元数据 <em>（Catalog）</em> 绑定，得到<em>Resolved Logical Plan（Analyzed Logical Plan）</em></li>
<li>逻辑优化：使用<em>RBO</em>（逻辑优化规则）和<em>CBO</em>（成本优化规则）进行优化，得到新的语法树</li>
<li>物理计划：将<em>Logical Plan</em> 转换为多个<em>Physical Plans</em> ，使用<em>Cost Model</em> 选择最佳的<em>Physical Plans</em></li>
<li>代码生成：编译部分查询为<em>Java</em> 字节码<br>
<img src="https://yuncheng1998.github.io/post-images/1620289744620.svg" alt="" loading="lazy"></li>
</ol>
<h2 id="分析">分析</h2>
<p>Spark SQL 以一个需要计算的关系开始，其来自<em>SQL Parser</em>返回的抽象语法树*（AST）*或来自使用 API 构造的 DataFrame 对象。在两种情况下，关系可能包含<strong>未解析的属性引用或关系</strong>，例如：在 SQL 查询 <code>SELECT col FROM sales</code>，col 的类型，甚至是否是一个合法的列名，在我们查询表 sales 之前都是未知的。如果我们不知道其类型或者没有匹配到输入表（或别名），那么这个属性就未被解析。<em>Spark SQL</em> 使用 <em>Catalyst</em> 规则和一个 <em>Catalyst</em> 对象去追踪所有数据源的表来解析这些属性。从未绑定的属性和数据类型构建一个<strong>未解析的逻辑计划</strong>，然后应用规则执行下面的步骤：</p>
<ol>
<li>通过名字从 <em>Catalog</em> 中查找关系。</li>
<li>映射命名属性，如 <em>col</em>，到输入的给定操作符子项。</li>
<li>检查哪些属性<strong>引用了相同的值</strong>给它们<strong>一个相同的 ID</strong>（之后允许针对 <code>col = col</code> 这样的表达式进行优化）。</li>
<li>通过表达式传递和强制类型：举个例子，我们无法知道 <code>1 + col</code> 的返回类型，直到解析 col 并可能将其子表达式转换为兼容类型。</li>
</ol>
<p><a href="https://github.com/apache/spark/blob/fedbfc7074dd6d38dc5301d66d1ca097bc2a21e0/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/Analyzer.scala">Analyzer.scala</a>。</p>
<h2 id="逻辑优化">逻辑优化</h2>
<p>逻辑优化阶段对逻辑计划应用标准的<strong>基于规则的优化</strong>。这些规则包括：常数折叠（constant folding）、谓词下推（predicate pushdown）、投影剪枝（projection pruning）、空传播（null propagation）、布尔表达式简化（Boolean expression simplification）和其他规则。</p>
<p><a href="https://github.com/apache/spark/blob/fedbfc7074dd6d38dc5301d66d1ca097bc2a21e0/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/Optimizer.scala">Optimizer.scala</a>。</p>
<h2 id="物理计划">物理计划</h2>
<p><em>Spark SQL</em> 将一个逻辑计划使用匹配 <em>Spark</em> 执行引擎的物理操作符生成一个或多个的物理计划，然后应用<strong>成本模型</strong>选择其中一个。</p>
<p>基于成本的优化器只用于选择连接算法：对于已知的很小的关系，Spark SQL 使用 broadcast join（点对点的广播工具）。</p>
<p>物理计划同样执行<strong>基于规则的物理优化</strong>，如在一个 <em>Spark</em> 的 <em>map</em> 操作执行流水线投影*（Piplining Projection）*或过滤。除此之外，还可以从逻辑计划将操作推到支持谓词或投影下推的数据源。</p>
<p><a href="https://github.com/apache/spark/blob/fedbfc7074dd6d38dc5301d66d1ca097bc2a21e0/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala">SparkStrategies.scala</a>.</p>
<h2 id="代码生成">代码生成</h2>
<p>最后阶段包括是生成在机器上运行的 Java 字节码。因为 <em>Spark SQL</em> 经常对内存中的数据集进行操作，而处理是受 <em>cpu</em> 约束的，所以我们希望支持代码生成以加快执行速度。代码生成引擎相当于一个编译器，<em>Catalyst</em> 依赖于 <em>Scala</em> 语言的一个特殊功能——<strong>准引号</strong>，以简化代码生成。<em>Quasiquotes</em> <strong>允许用 <em>Scala</em> 语言编程构造 <em>AST</em></strong> ，然后在<strong>运行时将其提供给 <em>Scala</em> 编译器生成字节码</strong>。我们使用 <em>Catalyst</em> 将一个表示 <em>SQL</em> 表达式的树转换为一个表示 <em>Scala</em> 代码的 <em>AST</em> 来计算该表达式，然后编译并运行生成的代码。</p>
<p>以上面的 <em>Add</em>、 <em>Attribute</em> 和 <em>Literal</em> 树节点为例，它允许我们编写如 <em>(x + y) + 1</em> 之类的表达式。如果没有代码生成，则必须通过遍历 <em>Add</em>、 <em>Attribute</em> 和 <em>Literal</em> 节点的树来解释每一行数据中的这类表达式，这将引入大量分支和虚函数调用，从而降低执行速度。通过代码生成，我们可以编写一个函数将特定的表达式树转换为 <em>Scala AST</em>，如下所示:</p>
<pre><code class="language-scala">def compile(node: Node): AST = node match {
  // 常量
  case Literal(value) =&gt; q&quot;$value&quot;
	// 属性
  case Attribute(name) =&gt; q&quot;row.get($name)&quot;
	// 操作符 ”+“
  case Add(left, right) =&gt; q&quot;${compile(left)} + ${compile(right)}&quot;
}
</code></pre>
<p>以 <em>q</em> 开头的字符串是准引号，尽管看起来像字符串，但在编译时被 <em>Scala</em> 编译器解析，并表示其中代码的 <em>AST</em>。</p>
<p><em>Quasiquotes</em> 可以将变量或其他 <em>AST</em> 拼接到这些变量中，并使用 <em>$</em> 符号表示。例如，<em>Literal (1)</em> 将成为1的 Scala AST，而 *Attribute (“x”)*将成为 <em>row.get (“x”)</em>。最后，像 <em>Add (Literal (1) ，Attribute (“x”)</em> 这样的树会成为 <em>Scala</em> 表达式的 <em>AST</em>：<em>1+row.get (“x”)</em>。</p>
<p><em>Quasiquotes</em> 会在编译时进行类型检查以确保只有合适的 <em>ASTs</em> 或者字面量能够被替换，这比字符串连接更有用，而且是<strong>直接生成 <em>Scala AST</em> 树</strong>而不是在运行时运行 <em>Scala</em> 解析器。此外，由于每个节点代码的生成规则不需要知晓其子节点是如何构建的，因此它们是高度可组合的。最后，如果 <em>Catalyst</em> 缺少表达式级别的优化，<em>Scala</em> 编译器会对代码进行进一步的优化。<br>
<a href="https://github.com/apache/spark/blob/fedbfc7074dd6d38dc5301d66d1ca097bc2a21e0/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/codegen/CodeGenerator.scala">CodeGenerator.scala</a>。</p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li><a href="#%E5%89%8D%E8%A8%80">前言</a></li>
<li><a href="#catalyst-%E7%9A%84%E6%A0%B8%E5%BF%83"><em>Catalyst</em> 的核心</a>
<ul>
<li><a href="#%E6%A0%91">树</a></li>
<li><a href="#%E8%A7%84%E5%88%99">规则</a></li>
</ul>
</li>
<li><a href="#%E5%9C%A8-spark-sql-%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8">在 <em>Spark SQL</em> 中的使用</a>
<ul>
<li><a href="#%E5%88%86%E6%9E%90">分析</a></li>
<li><a href="#%E9%80%BB%E8%BE%91%E4%BC%98%E5%8C%96">逻辑优化</a></li>
<li><a href="#%E7%89%A9%E7%90%86%E8%AE%A1%E5%88%92">物理计划</a></li>
<li><a href="#%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90">代码生成</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://yuncheng1998.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
